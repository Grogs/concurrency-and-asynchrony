<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/sky.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
		<style>
			.reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {
				text-transform: none;
			}
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown
						 data-separator="^\n\n\n"
						 data-separator-vertical="^\n\n"
						 data-separator-notes="^Note:">



					Throttling Futures
					Note:
					I just went into a lot of detail about some of the subtilties of how to avoid some pitfalls with Fures. Let's take a step and look at their usage.


					map and flatMap:
					```scala
					def fetchOldDoc(id: Int): Future[String]
					def transform(oldDoc: String): String
					def upload(doc: String): Future[Unit]

					def update(id: Int): Future[Unit] = {
					fetchOldDoc(id).map(transform).flatMap(upload)
					}
					```


					for-comprehensions:
					```scala
					def fetchOldDoc(id: Int): Future[String]
					def transform(oldDoc: String): String
					def upload(doc: String): Future[Unit]

					def update(id: Int): Future[Unit] = {
					for {
					old     <- fetchOldDoc(id)
					updated  = transform(old)
					_       <- upload(updated)
					} yield ()
					}
					```


					working with multiple futures:
					```scala
					def update(id: Int): Future[Unit]
					val ids: Seq[int]

					id.foreach(update)
					```



					## Parallel Futures
					```scala
					for {
					_ <- upload(docA)
					_ <- upload(docB)
					} yield ()
					//versus
					val eventualA = upload(docA)
					val eventualB = upload(docB)
					for {
					_ <- eventualA
					_ <- eventualB
					} yield ()
					```


					## Future.traverse
					```scala
					def upload(doc: String): Unit = ...
					val docs: Seq[String] = ...

					def uploadAll(docs: List[String]): Future[Unit] = {
					???
					}
					```


					What if there are a lot of documents?
					Note:
					- We're using async libraries for calling webservices or inserting to cassandra.
					- And say we have a lot of documents (let's say 1000 or 10k).
					- Futures are eager. If I traverse a list of 1000 items, we'll immediately kick off 1000 Futures.
					- We often don't actually want to do that. The web service or database you're calling might not handle that.


					Use case: Batch job

					"Fetch the latest review score for 300k hotels and write to a database"]
					Note:
					- Let's say I have a batch job to update the review score for the whole inventory of hotels.
					- This is a usecase I've come across a number of times.


					```scala
					def fetchIds(): Future[Seq[Id]] = ... //100k IDs
					def fetchScore(id: Id): Future[(Id, Score)] = ...
					def persist(idScorePair: (Id, Score)): Future[Unit] = ...

					for {
					ids    <- fetchIds()
					scores <- Future.traverse(ids)(fetchScore)
					_      <- Future.traverse(scores)(persist)
					} yield ()
					```

					However:
					- Future.traverse is eager
					- Nothing in standard library to throttle it.
					Note:
					- Future.traverse eagerly schedules kicks off every Future immediately!
					- For blocking code wrapped in Futures, you can manage concurrency through the execution context.
					- But what about with real async libraries?
					- Then I have a problem. If I fetch scores from a web service, it may not be able to handle that much traffic, and my Futures will fail.
					- Or by doing lots of database writes at the end, you can degrade your datbase's read performance. That's an issue I've had with Cassandra.





					## Akka Actors

					Good for working with state in a concurrent system...
					...Which is a problem I try to avoid.

					Note:
					- Solves concurrency issues by not processing messages concurrently.
					- helps solves issues related to concurrent access/modification around state.
					- Often you don't have state in your application; instead you an push it out to a database.
					- Actors don't tackle long-running IO and problems associated with it.
					- So although I've used it before, I've not really had a usecase where it's needed (instead of offloading to a DB).


					...Then I changed jobs...
					Note:
					- Until a couple of years ago, that was my understanding: "Use Futures, avoid blocking IO. I don't need Akka."
					- Then I started working in a team using async libraries for all IO, and Akka Streams to read from kafka topics.
					- I ended up revisiting both Akka and Futures, and so I want to share how my understanding evolved.





					RateLimiter


				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
            // Reveal.configure({ slideNumber: 'c/t' });
            // Reveal.configure({ showSlideNumber: 'speaker' });

            // More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				history: true,
                controlsTutorial: false,
                slideNumber: 'c/t',
                showSlideNumber: 'speaker',
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
